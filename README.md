# POC: Compara√ß√£o entre Go com Apache Beam e Python com Apache Spark para Pipelines de Dados

## 1. Objetivo

Esta Prova de Conceito (POC) tem como objetivo avaliar e comparar duas abordagens modernas para a constru√ß√£o de pipelines de dados: **Go com Apache Beam** e **Python com Apache Spark**. A an√°lise considera aspectos cruciais como:

* Velocidade de ingest√£o de dados
* Capacidade de lidar com opera√ß√µes de processamento complexas
* Facilidade de implementa√ß√£o e manuten√ß√£o
* Suporte a m√∫ltiplos formatos de arquivos
* Adequa√ß√£o ao mercado profissional

Ao final, a POC buscar√° identificar qual abordagem oferece o melhor equil√≠brio entre performance, escalabilidade e produtividade para apoiar decis√µes t√©cnicas mais assertivas no projeto.

---

## 2. Motiva√ß√£o

A crescente demanda por solu√ß√µes escal√°veis, perform√°ticas e flex√≠veis no processamento de dados imp√µe desafios importantes para times de engenharia. Diante disso, torna-se essencial escolher tecnologias que n√£o apenas atendam aos requisitos t√©cnicos, mas que tamb√©m sejam sustent√°veis no longo prazo.

Esta POC surge da necessidade de testar, na pr√°tica, alternativas modernas ao modelo tradicional de pipelines, considerando linguagens emergentes como Go, aliadas a frameworks robustos como Apache Beam. Ao mesmo tempo, exploramos a maturidade e o ecossistema consolidado do Apache Spark com Python, amplamente adotado na ind√∫stria.

A iniciativa visa embasar a escolha tecnol√≥gica com evid√™ncias concretas, permitindo decis√µes mais fundamentadas e alinhadas com os objetivos do projeto, promovendo inova√ß√£o com responsabilidade t√©cnica.

---

## 3. Escopo da POC

* **Formatos de entrada:** CSV, JSON, Parquet, Avro, XML, ORC e Delta
* **Opera√ß√µes a serem avaliadas:** agrega√ß√µes, joins, filtros complexos
* **Volumes de teste:** 1 GB e 10 GB
* **Fora do escopo:** integra√ß√µes externas, seguran√ßa e orquestra√ß√£o

---

## 4. Crit√©rios de Avalia√ß√£o e M√©tricas

### 4.1 Velocidade de Ingest√£o

* **M√©trica:** Tempo total de ingest√£o (em segundos)
* **Como medir:** Cronometrar o tempo de execu√ß√£o dos pipelines
* **Ferramentas:** Logs, profiler, ferramentas de monitoramento de sistema

### 4.2 Capacidade de Processamento Complexo

* **M√©trica:** Tempo de execu√ß√£o de opera√ß√µes complexas
* **Como medir:** Implementar e medir o tempo de execu√ß√µes espec√≠ficas
* **Avalia√ß√£o qualitativa:** Facilidade de implementa√ß√£o e legibilidade do c√≥digo

### 4.3 Facilidade de Implementa√ß√£o Multiformato

* **M√©trica:** Tempo de desenvolvimento (horas/dias)
* **Avalia√ß√£o qualitativa:** Qualidade da documenta√ß√£o, suporte da comunidade e bibliotecas dispon√≠veis

### 4.4 Viabilidade de Mercado

* **M√©trica qualitativa:**

  * Volume de vagas no mercado relacionadas a Go/Beam e Spark
  * Tamanho da comunidade, treinamentos, eventos e materiais dispon√≠veis

---

## Setup e Execu√ß√£o do Ambiente

Todos os scripts e instru√ß√µes para preparar o ambiente, instalar depend√™ncias e baixar o dataset de teste est√£o localizados na pasta `prep_ambiente`.

**‚û°Ô∏è Acesse o guia de prepara√ß√£o do ambiente local**

Como alternativa √† configura√ß√£o manual, voc√™ pode usar um ambiente Docker pr√©-configurado. As instru√ß√µes est√£o na pasta `infra`. **‚û°Ô∏è Acesse o guia de prepara√ß√£o do ambiente Docker**

---

## 5. Plano de Execu√ß√£o

| Etapa                 | Descri√ß√£o                                   | Respons√°vel | Prazo |
| --------------------- | ------------------------------------------- | ----------- | ----- |
| Levantamento de dados | Obter datasets de refer√™ncia                |             |       |
| Implementa√ß√£o Go      | Desenvolver o pipeline utilizando Go + Beam |             |       |
| Implementa√ß√£o Spark   | Desenvolver o pipeline com Python + Spark   |             |       |
| Testes de performance | Executar e coletar m√©tricas                 |             |       |
| An√°lise de mercado    | Levantamento de dados e tend√™ncias          |             |       |
| Documenta√ß√£o final    | Consolida√ß√£o dos resultados e conclus√µes    |             |       |

---

## 6. Ferramentas e Tecnologias

* **Go:** (vers√£o), bibliotecas utilizadas (ex: `encoding/csv`, `parquet-go`)
* **Apache Spark:** (vers√£o), linguagem (PySpark ou Scala)
* **Ambiente:** Descri√ß√£o da infraestrutura de execu√ß√£o e testes

---

## 7. Riscos e Mitiga√ß√µes

| Risco                                                                    | Mitiga√ß√£o                                                        |
| ------------------------------------------------------------------------ | ---------------------------------------------------------------- |
| Diferen√ßas de maturidade entre as bibliotecas podem afetar os resultados | Documentar as limita√ß√µes e ajustar os testes conforme necess√°rio |
| Curva de aprendizado do Spark pode aumentar o tempo de desenvolvimento   | Adotar exemplos pr√°ticos e documenta√ß√£o oficial como apoio       |
| Infraestrutura desigual pode enviesar os resultados                      | Garantir equival√™ncia de recursos computacionais nos testes      |

---

## 8. Conceito dos Formatos de Arquivo

**1. CSV (Comma Separated Values)**

* Formato simples baseado em texto
* Ampla compatibilidade com sistemas
* Pouco eficiente para an√°lises em larga escala

**2. JSON (JavaScript Object Notation)**

* Baseado em texto, leg√≠vel por humanos
* Ideal para troca de dados entre sistemas heterog√™neos
* Suportado amplamente em APIs e aplica√ß√µes web

**3. Parquet (Formato colunar)**

* Otimizado para leitura de colunas espec√≠ficas
* Alta taxa de compress√£o e efici√™ncia para Big Data
* Preserva tipagem e √© compat√≠vel com ecossistemas como Spark, Hive

**4. Avro (Formato bin√°rio)**

* Bin√°rio, compacto e com suporte a esquemas
* Alta compatibilidade com sistemas Hadoop
* Ideal para transporte e serializa√ß√£o de dados

**5. XML (Extensible Markup Language)**

* Estrutura hier√°rquica com tags personalizadas
* Suportado em diversas plataformas
* Mais verboso que JSON, por√©m mais flex√≠vel em estrutura

**6. ORC (Optimized Row Columnar)**

* Formato colunar otimizado para Hive/Spark
* Alta compress√£o e performance de leitura
* Suporte a estat√≠sticas e tipos complexos

**7. Delta (Delta Lake)**

* Baseado em Parquet com suporte a transa√ß√µes ACID
* Ideal para cen√°rios com atualiza√ß√£o e versionamento de dados
* Usado em pipelines incrementais e processamento de dados em tempo real

---

## 9. Tabela Comparativa de Formatos

| Formato     | Caracter√≠sticas Principais          | Uso T√≠pico                                       |
| ----------- | ----------------------------------- | ------------------------------------------------ |
| **CSV**     | Texto simples, baixa efici√™ncia     | Pequenos conjuntos de dados, interoperabilidade  |
| **JSON**    | Texto estruturado, leg√≠vel e leve   | Integra√ß√£o entre sistemas, APIs                  |
| **Parquet** | Colunar, eficiente e comprimido     | Big Data e consultas anal√≠ticas                  |
| **Avro**    | Bin√°rio, com esquema e compacto     | Serializa√ß√£o de dados em pipelines               |
| **XML**     | Estrutura hier√°rquica e flex√≠vel    | Interc√¢mbio de dados em sistemas legados         |
| **ORC**     | Colunar com compress√£o eficiente    | Hive e Spark para grandes volumes                |
| **Delta**   | Controle de vers√£o, transa√ß√µes ACID | Data Lakes din√¢micos e pipelines com atualiza√ß√£o |

---

## 10. Dataset Base

Ser√° utilizado como base de testes o dataset p√∫blico do Kaggle:
üîó [State of Data - Brazil 2023](https://www.kaggle.com/datasets/datahackers/state-of-data-brazil-2023)

Este conjunto ser√° processado pelo script `geraDados.py`, que gerar√° vers√µes com tamanhos de **1 GB** e **10 GB** nos diferentes formatos listados acima.
